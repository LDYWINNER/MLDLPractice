{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Main contents summarized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b602a8a717baecda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### #4 CNN(LeNet, VGG, Resnet, GoogleNet)\n",
    "\n",
    "- Simple architecture of CNN: \n",
    "    - convolutional layer\n",
    "    - activation layer\n",
    "    - pooling layer\n",
    "    - fully connected layer\n",
    "- We repeat convolutional, activation, pooling layer many times and then flatten the output feature map and then give it to the fully connected feedforward network (MLP)\n",
    "\n",
    "- Popular CNNs\n",
    "    - LeNet: first successful applications of CNN (read zip codes and digits)\n",
    "    - AlexNet: first work that popularized CNN in Computer vision\n",
    "        - very similar architecture with LeNet but was deeper, bigger, and featured convolutional layers stacked on top of each other (previously it was common to only have a single convolutional layer always immediately followed by pooling layer)\n",
    "    - GoogLeNet: main contribution was the development of an Inception module that dramatically reduced the number of parameters in the network(4M compared to AlexNet with 60M)\n",
    "        - uses Average pooling instead of fully connected layers at the top of the convolutional network, eliminating large amount of parameters that do not seem to matter much\n",
    "    - VGGNet: showed the depth of the network is a critical component for good performance\n",
    "        - its final best network contains 16 convolutional/fully connected layers and appealingly features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end\n",
    "        - downside: more expensive to evaluate and uses a lot more memory and parameters(140M)\n",
    "        - most of these params are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters\n",
    "    - ResNet: most commonly used\n",
    "        - features special skip connections and a heavy use of batch normalization\n",
    "        - latest CNN + default choice for using CNN in practice\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "282cc07bde0e40ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### #5 Image Classification with single label and multi-label\n",
    "\n",
    "- Image classification: computer vision task to recognize input image and predict a single-label or multi-label for the image as output using ML(DL) techniques\n",
    "\n",
    "### #6 PreTrained Models and their applications\n",
    "\n",
    "- Pre-trained models are open-source Deep Neural Network models trained on large benchmark datasets\n",
    "- Initially, Students and researchers can use these latest models instead of reinventing everything from scratch\n",
    "- The Deep Learning community has greatly benefitted from these open-source models where pre-trained models are a major reason for rapid advancements in the Computer Vision and deep learning research\n",
    "\n",
    "- Why use pretrained models?\n",
    "    - pre-trained models are used for transfer learning(전이학습) that is the major reason behind the concept of pre-trained models\n",
    "        - we can prevent reinventing everything from scratch\n",
    "    - the reuse of pre-trained models on a new problem is known as transfer learning in machine learning\n",
    "        - Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned using pre-trained model\n",
    "    - In transfer learning, we can train the model on our own data set using the learned knowledge of the pre-trained model\n",
    "\n",
    "- We will use 1. ResNet 2. AlexNet\n",
    "    - Both networks have been trained on ImageNet dataset(very large: 14 million images with 1000 classes maintained by Stanford univ)\n",
    "    - ImageNet dataset extensively used for a large variety of image related dl projects"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4308f0969689ad6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### #7 Deep Learning ResNet and AlexNet Architectures for Image classification\n",
    "\n",
    "- Deep Residual Network (ResNet)\n",
    "    - ResNet is a deep convolutional neural network proposed for image classification and recognition\n",
    "    - It has powerful representational capability for learning discriminative feature from complex scenes\n",
    "    - ResNet network architecture designed for classification task, trained on the imageNet dataset of natural scenes that consists of 1000 classes\n",
    "    - Deep Residual Network (ResNet) consists of depths with 18-layers, 34-layers, 50-layers, 101-layers and 152-layers\n",
    "        - They are variations of ResNet\n",
    "        - As we go deeper, computational cost increases as there are a large number of parameters with large number of layers\n",
    "        - However, the performance increases from lower layer ResNet to higher ones\n",
    "        - ResNet with 50 layers (ResNet-50) is suggested because it is used extensively in research area\n",
    "            - But it depends on the dataset and the number of classes we have\n",
    "            - If we have smaller dataset with smaller number of classes, it is possible that we can use ResNet-34 and it will fill our requirement  \n",
    "    - Deep residual nets won the 1st place on the ILSVRC 2015 classification challenge\n",
    "\n",
    "- AlexNet\n",
    "    - deep convolutional neural network trained on ImageNet dataset to classify the images into 1000 classes\n",
    "    - It has 5 convolutional layers followed by max-pooling layers and 3 fully connected layers\n",
    "    - won the ILSVRC 2012 classification challenge"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daebee5f4cb2c934"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "65d92f43fc3f7dfb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
